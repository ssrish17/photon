From 788deeb00d5b2c6329c9ee08f20ef3dda79db93a Mon Sep 17 00:00:00 2001
From: Bo Gan <ganb@vmware.com>
Date: Tue, 2 Jun 2020 19:25:06 -0700
Subject: [PATCH] x86/vmware: Use Efficient and Correct ALTERNATIVEs for
 hypercall

Before ALTERNATIVEs are applied, vmware_hypercall_mode will be used
to select hypercall methods (IO/VMCALL/VMMCALL). Hypercall goes
through vmw_hypercall(hb)_slowpath. After ALTERNATIVEs are applied,
the call instruction will be replaced with IO/VMCALL/VMMCALL
instructions.

Signed-off-by: Bo Gan <ganb@vmware.com>
---
 MAINTAINERS                           |  1 +
 arch/x86/include/asm/asm-prototypes.h |  1 +
 arch/x86/include/asm/vmware.h         | 52 +++++++++++++++++----
 arch/x86/kernel/cpu/Makefile          |  2 +-
 arch/x86/kernel/cpu/vmw_hc.S          | 61 +++++++++++++++++++++++++
 arch/x86/kernel/cpu/vmware.c          | 66 +++++++++++++--------------
 6 files changed, 137 insertions(+), 46 deletions(-)
 create mode 100644 arch/x86/kernel/cpu/vmw_hc.S

diff --git a/MAINTAINERS b/MAINTAINERS
index 72b9654f764c..f86bbb90061b 100644
--- a/MAINTAINERS
+++ b/MAINTAINERS
@@ -21719,6 +21719,7 @@ L:	x86@kernel.org
 S:	Supported
 T:	git git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip.git x86/vmware
 F:	arch/x86/include/asm/vmware.h
+F:	arch/x86/kernel/cpu/vmw_hc.S
 F:	arch/x86/kernel/cpu/vmware.c
 
 VMWARE PVRDMA DRIVER
diff --git a/arch/x86/include/asm/asm-prototypes.h b/arch/x86/include/asm/asm-prototypes.h
index 5cdccea45..89c1ed6c5 100644
--- a/arch/x86/include/asm/asm-prototypes.h
+++ b/arch/x86/include/asm/asm-prototypes.h
@@ -13,6 +13,7 @@
 #include <asm/preempt.h>
 #include <asm/asm.h>
 #include <asm/nospec-branch.h>
+#include <asm/vmware.h>

 #ifndef CONFIG_X86_CMPXCHG64
 extern void cmpxchg8b_emu(void);
diff --git a/arch/x86/include/asm/vmware.h b/arch/x86/include/asm/vmware.h
index ac9fc51e2b18..e9e9a91455e0 100644
--- a/arch/x86/include/asm/vmware.h
+++ b/arch/x86/include/asm/vmware.h
@@ -2,10 +2,16 @@
 #ifndef _ASM_X86_VMWARE_H
 #define _ASM_X86_VMWARE_H
 
+#include <linux/bits.h>
 #include <asm/cpufeatures.h>
 #include <asm/alternative.h>
 #include <linux/stringify.h>
 
+#define CPUID_VMWARE_INFO_LEAF               0x40000000
+#define CPUID_VMWARE_FEATURES_LEAF           0x40000010
+#define CPUID_VMWARE_FEATURES_ECX_VMMCALL    BIT(0)
+#define CPUID_VMWARE_FEATURES_ECX_VMCALL     BIT(1)
+
 /*
  * The hypercall definitions differ in the low word of the %edx argument
  * in the following way: the old port base interface uses the port
@@ -28,30 +34,56 @@
 #define VMWARE_HYPERVISOR_HB   BIT(0)
 #define VMWARE_HYPERVISOR_OUT  BIT(1)
 
+#ifndef __ASSEMBLY__
+/*
+ * Custom calling convention defined by hypervisor.
+ * Function itself should not clobber any register.
+ */
+extern void vmw_hypercall_slowpath(void);
+extern void vmw_hypercall_hb_out_slowpath(void);
+extern void vmw_hypercall_hb_in_slowpath(void);
+#endif
+
 /* The low bandwidth call. The low word of edx is presumed clear. */
 #define VMWARE_HYPERCALL						\
-	ALTERNATIVE_2("movw $" __stringify(VMWARE_HYPERVISOR_PORT) ", %%dx; " \
-		      "inl (%%dx), %%eax",				\
+	ALTERNATIVE_3("callq vmw_hypercall_slowpath",			\
+		      "movw $" __stringify(VMWARE_HYPERVISOR_PORT)	\
+							", %%dx; "	\
+		      "inl (%%dx), %%eax", X86_FEATURE_HYPERVISOR,	\
+		      "movw $0, %%dx; "					\
 		      "vmcall", X86_FEATURE_VMCALL,			\
+		      "movw $0, %%dx; "					\
 		      "vmmcall", X86_FEATURE_VMW_VMMCALL)
 
 /*
- * The high bandwidth out call. The low word of edx is presumed to have the
- * HB and OUT bits set.
+ * The high bandwidth out call.
  */
 #define VMWARE_HYPERCALL_HB_OUT						\
-	ALTERNATIVE_2("movw $" __stringify(VMWARE_HYPERVISOR_PORT_HB) ", %%dx; " \
-		      "rep outsb",					\
+	ALTERNATIVE_3("callq vmw_hypercall_hb_out_slowpath",		\
+		      "movw $" __stringify(VMWARE_HYPERVISOR_PORT_HB)	\
+							", %%dx; "	\
+		      "cld; rep outsb", X86_FEATURE_HYPERVISOR,		\
+		      "movw $" __stringify(VMWARE_HYPERVISOR_HB |	\
+					   VMWARE_HYPERVISOR_OUT)	\
+							", %%dx; "	\
 		      "vmcall", X86_FEATURE_VMCALL,			\
+		      "movw $" __stringify(VMWARE_HYPERVISOR_HB |	\
+					   VMWARE_HYPERVISOR_OUT)	\
+							", %%dx; "	\
 		      "vmmcall", X86_FEATURE_VMW_VMMCALL)
 
 /*
- * The high bandwidth in call. The low word of edx is presumed to have the
- * HB bit set.
+ * The high bandwidth in call.
  */
 #define VMWARE_HYPERCALL_HB_IN						\
-	ALTERNATIVE_2("movw $" __stringify(VMWARE_HYPERVISOR_PORT_HB) ", %%dx; " \
-		      "rep insb",					\
+	ALTERNATIVE_3("callq vmw_hypercall_hb_in_slowpath",		\
+		      "movw $" __stringify(VMWARE_HYPERVISOR_PORT_HB)	\
+							", %%dx; "	\
+		      "cld; rep insb", X86_FEATURE_HYPERVISOR,		\
+		      "movw $" __stringify(VMWARE_HYPERVISOR_HB)	\
+							", %%dx; "	\
 		      "vmcall", X86_FEATURE_VMCALL,			\
+		      "movw $" __stringify(VMWARE_HYPERVISOR_HB)	\
+							", %%dx; "	\
 		      "vmmcall", X86_FEATURE_VMW_VMMCALL)
 #endif
diff --git a/arch/x86/kernel/cpu/Makefile b/arch/x86/kernel/cpu/Makefile
index 9661e3e802be..89c96c936083 100644
--- a/arch/x86/kernel/cpu/Makefile
+++ b/arch/x86/kernel/cpu/Makefile
@@ -53,7 +53,7 @@ obj-$(CONFIG_X86_SGX)			+= sgx/
 
 obj-$(CONFIG_X86_LOCAL_APIC)		+= perfctr-watchdog.o
 
-obj-$(CONFIG_HYPERVISOR_GUEST)		+= vmware.o hypervisor.o mshyperv.o
+obj-$(CONFIG_HYPERVISOR_GUEST)		+= vmware.o vmw_hc.o hypervisor.o mshyperv.o
 obj-$(CONFIG_ACRN_GUEST)		+= acrn.o
 
 ifdef CONFIG_X86_FEATURE_NAMES
diff --git a/arch/x86/kernel/cpu/vmw_hc.S b/arch/x86/kernel/cpu/vmw_hc.S
new file mode 100644
index 000000000000..3a5adb77baab
--- /dev/null
+++ b/arch/x86/kernel/cpu/vmw_hc.S
@@ -0,0 +1,61 @@
+/* SPDX-License-Identifier: GPL-2.0+ */
+
+#include <linux/linkage.h>
+#include <asm/export.h>
+#include <asm/vmware.h>
+
+	.text
+SYM_FUNC_START(vmw_hypercall_slowpath)
+	testb	$CPUID_VMWARE_FEATURES_ECX_VMMCALL, vmware_hypercall_mode(%rip)
+	jnz	.Lvmw_vmmcall
+	testb	$CPUID_VMWARE_FEATURES_ECX_VMCALL, vmware_hypercall_mode(%rip)
+	jnz	.Lvmw_vmcall
+	movw	$VMWARE_HYPERVISOR_PORT, %dx;
+	inl	(%dx), %eax
+	RET
+.Lvmw_vmcall:
+	movw	$0, %dx
+	vmcall
+	RET
+.Lvmw_vmmcall:
+	movw	$0, %dx
+	vmmcall
+	RET
+SYM_FUNC_END(vmw_hypercall_slowpath)
+EXPORT_SYMBOL(vmw_hypercall_slowpath)
+
+SYM_FUNC_START(vmw_hypercall_hb_out_slowpath)
+	movw	$(VMWARE_HYPERVISOR_HB | VMWARE_HYPERVISOR_OUT), %dx
+	testb	$CPUID_VMWARE_FEATURES_ECX_VMMCALL, vmware_hypercall_mode(%rip)
+	jnz	.Lvmw_vmmcallo
+	testb	$CPUID_VMWARE_FEATURES_ECX_VMCALL, vmware_hypercall_mode(%rip)
+	jnz	.Lvmw_vmcallo
+	movw	$VMWARE_HYPERVISOR_PORT_HB, %dx
+	rep outsb
+	RET
+.Lvmw_vmcallo:
+	vmcall
+	RET
+.Lvmw_vmmcallo:
+	vmmcall
+	RET
+SYM_FUNC_END(vmw_hypercall_hb_out_slowpath)
+EXPORT_SYMBOL(vmw_hypercall_hb_out_slowpath)
+
+SYM_FUNC_START(vmw_hypercall_hb_in_slowpath)
+	movw	$VMWARE_HYPERVISOR_HB, %dx
+	testb	$CPUID_VMWARE_FEATURES_ECX_VMMCALL, vmware_hypercall_mode(%rip)
+	jnz	.Lvmw_vmmcalli
+	testb	$CPUID_VMWARE_FEATURES_ECX_VMCALL, vmware_hypercall_mode(%rip)
+	jnz	.Lvmw_vmcalli
+	movw	$VMWARE_HYPERVISOR_PORT_HB, %dx
+	rep insb
+	RET
+.Lvmw_vmcalli:
+	vmcall
+	RET
+.Lvmw_vmmcalli:
+	vmmcall
+	RET
+SYM_FUNC_END(vmw_hypercall_hb_in_slowpath)
+EXPORT_SYMBOL(vmw_hypercall_hb_in_slowpath)
diff --git a/arch/x86/kernel/cpu/vmware.c b/arch/x86/kernel/cpu/vmware.c
index 02039ec3597d..64bc42214054 100644
--- a/arch/x86/kernel/cpu/vmware.c
+++ b/arch/x86/kernel/cpu/vmware.c
@@ -39,11 +39,6 @@
 #undef pr_fmt
 #define pr_fmt(fmt)	"vmware: " fmt
 
-#define CPUID_VMWARE_INFO_LEAF               0x40000000
-#define CPUID_VMWARE_FEATURES_LEAF           0x40000010
-#define CPUID_VMWARE_FEATURES_ECX_VMMCALL    BIT(0)
-#define CPUID_VMWARE_FEATURES_ECX_VMCALL     BIT(1)
-
 #define VMWARE_HYPERVISOR_MAGIC	0x564D5868
 
 #define VMWARE_CMD_GETVERSION    10
@@ -57,44 +52,22 @@
 #define STEALCLOCK_DISABLED        0
 #define STEALCLOCK_ENABLED         1
 
-#define VMWARE_PORT(cmd, eax, ebx, ecx, edx)				\
-	__asm__("inl (%%dx), %%eax" :					\
-		"=a"(eax), "=c"(ecx), "=d"(edx), "=b"(ebx) :		\
-		"a"(VMWARE_HYPERVISOR_MAGIC),				\
-		"c"(VMWARE_CMD_##cmd),					\
-		"d"(VMWARE_HYPERVISOR_PORT), "b"(UINT_MAX) :		\
-		"memory")
-
-#define VMWARE_VMCALL(cmd, eax, ebx, ecx, edx)				\
-	__asm__("vmcall" :						\
+#define VMWARE_CMD(cmd, eax, ebx, ecx, edx)				\
+	__asm__(VMWARE_HYPERCALL :					\
 		"=a"(eax), "=c"(ecx), "=d"(edx), "=b"(ebx) :		\
 		"a"(VMWARE_HYPERVISOR_MAGIC),				\
 		"c"(VMWARE_CMD_##cmd),					\
 		"d"(0), "b"(UINT_MAX) :					\
 		"memory")
 
-#define VMWARE_VMMCALL(cmd, eax, ebx, ecx, edx)                         \
-	__asm__("vmmcall" :						\
-		"=a"(eax), "=c"(ecx), "=d"(edx), "=b"(ebx) :		\
+#define VMWARE_CMD_6(cmd, eax, ebx, ecx, edx, esi, edi)		\
+	__asm__(VMWARE_HYPERCALL :				        \
+		"=a"(eax), "=c"(ecx), "+d"(edx), "+b"(ebx),		\
+					"+S"(esi), "+D"(edi) :		\
 		"a"(VMWARE_HYPERVISOR_MAGIC),				\
-		"c"(VMWARE_CMD_##cmd),					\
-		"d"(0), "b"(UINT_MAX) :					\
+		"c"(VMWARE_CMD_##cmd) :					\
 		"memory")
 
-#define VMWARE_CMD(cmd, eax, ebx, ecx, edx) do {		\
-	switch (vmware_hypercall_mode) {			\
-	case CPUID_VMWARE_FEATURES_ECX_VMCALL:			\
-		VMWARE_VMCALL(cmd, eax, ebx, ecx, edx);		\
-		break;						\
-	case CPUID_VMWARE_FEATURES_ECX_VMMCALL:			\
-		VMWARE_VMMCALL(cmd, eax, ebx, ecx, edx);	\
-		break;						\
-	default:						\
-		VMWARE_PORT(cmd, eax, ebx, ecx, edx);		\
-		break;						\
-	}							\
-	} while (0)
-
 struct vmware_steal_time {
 	union {
 		uint64_t clock;	/* stolen time counter in units of vtsc */
@@ -107,8 +80,30 @@ struct vmware_steal_time {
 	uint64_t reserved[7];
 };
 
+#define VMWARE_HB_OUT(cmd, eax, ebx, ecx, edx, esi, edi, ebp)		\
+	__asm__("pushq %%rbp\n\t"					\
+		"movl %[extra], %%ebp\n\t"				\
+		VMWARE_HYPERCALL_HB_OUT					\
+		"popq %%rbp\n\t" :					\
+		"=a"(eax), "+c"(ecx), "+d"(edx), "=b"(ebx) :		\
+		"a"(VMWARE_HYPERVISOR_MAGIC),				\
+		"b"(VMWARE_HB_CMD_##cmd),				\
+		"S"(esi), "D"(edi), [extra] "r"(ebp) :			\
+		"memory")
+
+#define VMWARE_HB_IN(cmd, eax, ebx, ecx, edx, esi, edi, ebp)		\
+	__asm__("pushq %%rbp\n\t"					\
+		"movl %[extra], %%ebp\n\t"				\
+		VMWARE_HYPERCALL_HB_IN					\
+		"popq %%rbp\n\t" :					\
+		"=a"(eax), "+c"(ecx), "+d"(edx), "=b"(ebx) :		\
+		"a"(VMWARE_HYPERVISOR_MAGIC),				\
+		"b"(VMWARE_HB_CMD_##cmd),				\
+		"S"(esi), "D"(edi), [extra] "r"(ebp) :			\
+		"memory")
+
 static unsigned long vmware_tsc_khz __ro_after_init;
-static u8 vmware_hypercall_mode     __ro_after_init;
+u8 vmware_hypercall_mode     __ro_after_init;
 
 static inline int __vmware_platform(void)
 {
@@ -379,6 +374,7 @@ static void __init vmware_set_capabilities(void)
 {
 	setup_force_cpu_cap(X86_FEATURE_CONSTANT_TSC);
 	setup_force_cpu_cap(X86_FEATURE_TSC_RELIABLE);
+	setup_force_cpu_cap(X86_FEATURE_HYPERVISOR);
 	if (vmware_tsc_khz)
 		setup_force_cpu_cap(X86_FEATURE_TSC_KNOWN_FREQ);
 	if (vmware_hypercall_mode == CPUID_VMWARE_FEATURES_ECX_VMCALL)
-- 
2.25.1

